# intelligent_chatbot.py
"""
Intelligent Equestrian Chatbot - Main Orchestrator
Coordinates all components to answer questions about horses
"""

from graphdb_client import GraphDBClient
from intelligent_sparql_generator import IntelligentSPARQLGenerator
from llm_client import FrenchLLMClient
from context_builder import ContextBuilder
from config import GRAPHDB_ENDPOINT, VERBOSE, SHOW_SPARQL


class IntelligentEquestrianChatbot:
    """
    Main chatbot that orchestrates the entire GraphRAG pipeline
    """
    
    def __init__(
        self,
        graphdb_endpoint: str = GRAPHDB_ENDPOINT,
        language: str = "fr"
    ):
        """
        Initialize the chatbot
        
        Args:
            graphdb_endpoint: GraphDB SPARQL endpoint
            language: Response language (fr/en)
        """
        print(" Initialisation du Chatbot √âquestre Intelligent...")
        print(f"   Langue: {language.upper()}")
        print("   LLM: Local (LM Studio)")
        
        self.language = language
        
        # Initialize all components
        self.graphdb = GraphDBClient(graphdb_endpoint)
        self.llm = FrenchLLMClient(use_local=True)
        self.sparql_generator = IntelligentSPARQLGenerator(self.llm)
        self.context_builder = ContextBuilder()
        
        print("Chatbot initialis√©!\n")
    
    def answer_question(self, question: str, verbose: bool = VERBOSE) -> dict:
        """
        Answer a question about horses
        
        Args:
            question: User's question in natural language
            verbose: Show detailed steps
            
        Returns:
            Dictionary with answer and metadata
        """
        if verbose:
            print(f"\n{'='*80}")
            print(f"QUESTION: {question}")
            print(f"{'='*80}\n")
        
        # STEP 1: Generate SPARQL query
        if verbose:
            print("√âTAPE 1: G√©n√©ration de la requ√™te SPARQL...")
        
        try:
            query_result = self.sparql_generator.generate_sparql(question, self.language)
            sparql_query = query_result["sparql_query"]
            entities_used = query_result["entities_used"]
            relations_used = query_result["relations_used"]
            explanation = query_result["explanation"]
            
            if verbose:
                print("Requ√™te g√©n√©r√©e!\n")
                print(f"Entit√©s utilis√©es: {', '.join(entities_used) if entities_used else 'N/A'}")
                print(f"Relations utilis√©es: {', '.join(relations_used) if relations_used else 'N/A'}")
                print(f"Explication: {explanation}\n")
                
                if SHOW_SPARQL:
                    print("Requ√™te SPARQL:")
                    print("-" * 80)
                    for line in sparql_query.split('\n'):
                        print(f"  {line}")
                    print("-" * 80)
                    print()
        
        except Exception as e:
            error_msg = f"Erreur lors de la g√©n√©ration SPARQL: {str(e)}"
            print(f"{error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "question": question
            }
        
        # STEP 2: Execute SPARQL on GraphDB
        if verbose:
            print("√âTAPE 2: Ex√©cution de la requ√™te sur GraphDB...")
        
        try:
            results = self.graphdb.query(sparql_query)
            
            if not results or 'results' not in results:
                if verbose:
                    print("Aucun r√©sultat retourn√©\n")
                return {
                    "success": False,
                    "error": "Pas de r√©sultats",
                    "question": question,
                    "sparql_query": sparql_query
                }
            
            bindings = results['results']['bindings']
            results_count = len(bindings)
            
            if verbose:
                print(f"{results_count} r√©sultat(s) trouv√©(s)!\n")
        
        except Exception as e:
            error_msg = f"Erreur GraphDB: {str(e)}"
            print(f" {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "question": question,
                "sparql_query": sparql_query
            }
        
        # STEP 3: Build context
        if verbose:
            print("√âTAPE 3: Construction du contexte...")
        
        try:
            context = self.context_builder.format_results(bindings, explanation)
            
            if verbose:
                print(f"Contexte cr√©√© ({len(context)} caract√®res)\n")
        
        except Exception as e:
            error_msg = f"Erreur contexte: {str(e)}"
            print(f"{error_msg}")
            context = str(bindings)
        
        # STEP 4: Generate natural language answer
        if verbose:
            print(" √âTAPE 4: G√©n√©ration de la r√©ponse...")
        
        try:
            answer = self._generate_answer(question, context, results_count)
            
            if verbose:
                print("R√©ponse g√©n√©r√©e!\n")
        
        except Exception as e:
            error_msg = f"Erreur g√©n√©ration r√©ponse: {str(e)}"
            print(f"{error_msg}")
            answer = f"Erreur: {error_msg}"
        
        # STEP 5: Display answer
        if verbose:
            print("R√âPONSE FINALE:")
            print("=" * 80)
            print(answer)
            print("=" * 80)
            print()
        
        return {
            "success": True,
            "question": question,
            "sparql_query": sparql_query,
            "entities_used": entities_used,
            "relations_used": relations_used,
            "explanation": explanation,
            "results_count": results_count,
            "context": context,
            "answer": answer,
            "raw_results": results
        }
    
    def _generate_answer(self, question: str, context: str, results_count: int) -> str:
        """Generate natural language answer"""
        
        system_prompt = """Tu es un assistant expert en donn√©es √©questres.
Tu r√©ponds aux questions en te basant UNIQUEMENT sur le contexte fourni.
Tu r√©ponds en fran√ßais, de mani√®re claire, concise et naturelle.
Si l'information n'est pas dans le contexte, tu le dis clairement."""
        
        user_prompt = f"""Question: {question}

Contexte du graphe de connaissances ({results_count} r√©sultats):
{context}

R√©ponds √† la question en te basant uniquement sur ce contexte.
Sois pr√©cis, concis et naturel."""
        
        answer = self.llm.generate(user_prompt, system_prompt)
        return answer
    
    def chat(self):
        """Interactive chat mode"""
        
        print("\nüê¥ Chatbot √âquestre - Mode Interactif")
        print("=" * 80)
        print("Posez vos questions sur les chevaux, cavaliers, entra√Ænements, etc.")
        print("\nExemples de questions:")
        print("  - Quels sont tous les chevaux?")
        print("  - Quel cheval a particip√© √† quelle s√©ance d'entra√Ænement?")
        print("  - Quels sont les diff√©rents couplages cheval/cavalier?")
        print("  - Quel est la race du cheval?")
        print("\nTapez 'quit', 'exit' ou 'quitter' pour terminer.")
        print("=" * 80)
        
        while True:
            try:
                question = input("\nüê¥ Votre question: ").strip()
                
                if not question:
                    continue
                
                if question.lower() in ['quit', 'exit', 'quitter', 'bye']:
                    print("\nAu revoir!")
                    break
                
                self.answer_question(question, verbose=True)
                
            except KeyboardInterrupt:
                print("\n\n Au revoir!")
                break
            except Exception as e:
                print(f"\n Erreur: {e}")


# ============================================================================
# MAIN EXECUTION
# ============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Chatbot √âquestre Intelligent')
    parser.add_argument('--question', type=str, help='Poser une seule question')
    parser.add_argument('--quiet', action='store_true', help='Mode silencieux')
    
    args = parser.parse_args()
    
    # Create chatbot
    chatbot = IntelligentEquestrianChatbot()
    
    # Single question or interactive mode
    if args.question:
        verbose = not args.quiet
        chatbot.answer_question(args.question, verbose=verbose)
    else:
        chatbot.chat()
